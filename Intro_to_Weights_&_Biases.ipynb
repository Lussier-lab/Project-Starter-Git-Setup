{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ix6sBerD2i5s"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/intro/Intro_to_Weights_&_Biases.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<!--- @wandbcode{intro-colab} -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "506jep5u2i5w"
   },
   "source": [
    "<img src=\"http://wandb.me/logo-im-png\" width=\"400\" alt=\"Weights & Biases\" />\n",
    "<!--- @wandbcode{intro-colab} -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAOOEbJB2i5x"
   },
   "source": [
    "\n",
    "# üèÉ‚Äç‚ôÄÔ∏è Quickstart\n",
    "Use [Weights & Biases](https://wandb.ai) for machine learning experiment tracking, dataset versioning, and project collaboration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RI6tzpS92i5x"
   },
   "source": [
    "## ü§© A shared dashboard for your experiments\n",
    "\n",
    "With just a few lines of code,\n",
    "you'll get rich, interactive, shareable dashboards [which you can see yourself here](https://wandb.ai/wandb/wandb_example).\n",
    "![](https://i.imgur.com/Pell4Oo.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MOsXtq_k2i5y"
   },
   "source": [
    "\n",
    "## üîí Data & Privacy\n",
    "\n",
    "We take security very seriously, and our cloud-hosted dashboard uses industry standard best practices for encryption. If you're working with datasets that cannot leave your enterprise cluster, we have [on-prem](https://docs.wandb.com/self-hosted) installations available. \n",
    "\n",
    "It's also easy to download all your data and export it to other tools ‚Äî like custom analysis in a Jupyter notebook. Here's [more on our API](https://docs.wandb.com/library/api).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J7gkp9jk2i5y"
   },
   "source": [
    "## ü™Ñ Install `wandb` library and login\n",
    "\n",
    "\n",
    "Start by installing the library and logging in to your free account.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T16:56:50.778930Z",
     "start_time": "2023-01-05T16:56:41.212859Z"
    },
    "id": "ANl-8GwM2i5z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "autokeras 1.0.15 requires tensorflow>=2.3.0, which is not installed.\r\n",
      "pyppeteer 0.2.5 requires websockets<9.0,>=8.1, but you have websockets 9.1 which is incompatible.\u001b[0m\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb -qU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RIndGKcA4-IZ"
   },
   "source": [
    "## Logging in to W&B\n",
    "- You can explicitly login using `wandb login` or `wandb.login()` (See below)\n",
    "- Alternatively you can set environment variables. There are several env variables which you can set to change the behavior of W&B logging. The most important are:\n",
    "    - `WANDB_API_KEY` - find this in your \"Settings\" section under your profile \n",
    "    - `WANDB_BASE_URL` - this is the url of the W&B server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T16:56:55.837650Z",
     "start_time": "2023-01-05T16:56:55.100827Z"
    },
    "id": "K1z-CurK4XJh"
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T16:57:12.310721Z",
     "start_time": "2023-01-05T16:56:56.828353Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.research.cchmc.org/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for wandb.research.cchmc.org to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB login successful\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import copy\n",
    "from ignite.contrib.handlers.wandb_logger import *\n",
    "from tqdm import tqdm\n",
    "os.environ[\"WANDB_BASE_URL\"] = \"https://wandb.research.cchmc.org\"\n",
    "# os.environ[\"WANDB_API_KEY\"] = \"<INSERT API KEY>\"\n",
    "try:\n",
    "    success = wandb.login(\n",
    "        host=os.getenv(\"WANDB_BASE_URL\")\n",
    "    )  # , key=os.getenv(\"WANDB_API_KEY\"))\n",
    "    if success:\n",
    "        print(\"WandB login successful\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mc1uXnFE2i53"
   },
   "source": [
    "## üëü Run an experiment\n",
    "1Ô∏è‚É£. **Start a new run** and pass in hyperparameters to track\n",
    "\n",
    "2Ô∏è‚É£. **Log metrics** from training or evaluation\n",
    "\n",
    "3Ô∏è‚É£. **Visualize results** in the dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T16:57:27.839323Z",
     "start_time": "2023-01-05T16:57:15.588997Z"
    },
    "id": "bhBaBbYi2i54"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msomd7w\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "292de4bae0924715afbf6048dd970ad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.0166686469844232, max=1.0))‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem at: <ipython-input-4-011516d9fd9a> 7 <module>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_init.py\", line 1078, in init\n",
      "    run = wi.init()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_init.py\", line 697, in init\n",
      "    result = handle.wait(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/lib/mailbox.py\", line 259, in wait\n",
      "    raise MailboxError(\"transport failed\")\n",
      "wandb.errors.MailboxError: transport failed\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Abnormal program exit\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "problem",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMailboxError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1077\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1078\u001b[0;31m             \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1079\u001b[0m             \u001b[0mexcept_exit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_except_exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    696\u001b[0m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeliver_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m             result = handle.wait(\n\u001b[0m\u001b[1;32m    698\u001b[0m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_progress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_progress_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/wandb/sdk/lib/mailbox.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout, on_probe, on_progress, release)\u001b[0m\n\u001b[1;32m    258\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transport_keepalive_failed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mMailboxError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"transport failed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMailboxError\u001b[0m: transport failed",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-011516d9fd9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrun\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_runs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;31m# üêù 1Ô∏è‚É£ Start a new run to track this script\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   wandb.init(\n\u001b[0m\u001b[1;32m      8\u001b[0m       \u001b[0;31m# Set the project where this run will be logged\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"basic-intro\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1113\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mexcept_exit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"problem\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merror_seen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: problem"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Launch 5 simulated experiments\n",
    "total_runs = 1\n",
    "for run in range(total_runs):\n",
    "  # üêù 1Ô∏è‚É£ Start a new run to track this script\n",
    "  wandb.init(\n",
    "      # Set the project where this run will be logged\n",
    "      project=\"basic-intro\", \n",
    "      # Entity is the team which you belong to\n",
    "      entity=\"kenlee\",\n",
    "      # We pass a run name (otherwise it‚Äôll be randomly assigned, like sunshine-lollypop-10)\n",
    "      name=f\"experiment_{run}\", \n",
    "      # Pass in \"group\" and \"job_type\" fields to contextualize your run\n",
    "      group=\"MNIST Benchmark\",\n",
    "      job_type=\"model_training\",\n",
    "      # Track hyperparameters and run metadata\n",
    "      config={\n",
    "      \"learning_rate\": 0.02,\n",
    "      \"architecture\": \"CNN\",\n",
    "      \"dataset\": \"CIFAR-100\",\n",
    "      \"epochs\": 10,\n",
    "      })\n",
    "  \n",
    "  # This simple block simulates a training loop logging metrics\n",
    "  epochs = 10\n",
    "  offset = random.random() / 5\n",
    "  for epoch in range(2, epochs):\n",
    "      acc = 1 - 2 ** -epoch - random.random() / epoch - offset\n",
    "      loss = 2 ** -epoch + random.random() / epoch + offset\n",
    "      \n",
    "      # üêù 2Ô∏è‚É£ Log metrics from your script to W&B\n",
    "      wandb.log({\"acc\": acc, \"loss\": loss})\n",
    "      \n",
    "  # Mark the run as finished\n",
    "  wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T16:20:13.633760Z",
     "start_time": "2023-01-05T16:20:50.123Z"
    }
   },
   "outputs": [],
   "source": [
    "!export no_proxy=localhost,127.0.0.1,.chmcres.cchmc.org,ml-workspace-chad,minio-0,minio.research.cchmc.org,wandb.research.cchmc.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T16:20:13.634487Z",
     "start_time": "2023-01-05T16:20:50.124Z"
    }
   },
   "outputs": [],
   "source": [
    "!env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NuK56M562i55"
   },
   "source": [
    "3Ô∏è‚É£ You can find your interactive dashboard by clicking any of the  üëÜ wandb links above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bWzuUFJv2i57"
   },
   "source": [
    "# üî• Training a simple Pytorch NN\n",
    "\n",
    "üí™ Run this model to train a simple MNIST classifier, and click on the project page link to see your results stream in live to a W&B project.\n",
    "\n",
    "\n",
    "Any run in `wandb` automatically logs [metrics](https://docs.wandb.ai/ref/app/pages/run-page#charts-tab),\n",
    "[system information](https://docs.wandb.ai/ref/app/pages/run-page#system-tab),\n",
    "[hyperparameters](https://docs.wandb.ai/ref/app/pages/run-page#overview-tab),\n",
    "[terminal output](https://docs.wandb.ai/ref/app/pages/run-page#logs-tab) and\n",
    "you'll see an [interactive table](https://docs.wandb.ai/guides/data-vis)\n",
    "with model inputs and outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqEHA3n02i58"
   },
   "source": [
    "## Set up Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T16:20:13.635240Z",
     "start_time": "2023-01-05T16:20:50.124Z"
    },
    "id": "KjEk1Sev2i58"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "import wandb\n",
    "import math\n",
    "import random\n",
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def get_dataloader(is_train, batch_size, slice=5):\n",
    "    \"Get a training dataloader\"\n",
    "    full_dataset = torchvision.datasets.MNIST(root=\".\", train=is_train, transform=T.ToTensor(), download=True)\n",
    "    sub_dataset = torch.utils.data.Subset(full_dataset, indices=range(0, len(full_dataset), slice))\n",
    "    loader = torch.utils.data.DataLoader(dataset=sub_dataset, \n",
    "                                         batch_size=batch_size, \n",
    "                                         shuffle=True if is_train else False, \n",
    "                                         pin_memory=True, num_workers=2)\n",
    "    return loader\n",
    "\n",
    "def get_model(dropout):\n",
    "    \"A simple model\"\n",
    "    model = nn.Sequential(nn.Flatten(),\n",
    "                         nn.Linear(28*28, 256),\n",
    "                         nn.BatchNorm1d(256),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Dropout(dropout),\n",
    "                         nn.Linear(256,10)).to(device)\n",
    "    return model\n",
    "\n",
    "def validate_model(model, valid_dl, loss_func, log_images=False, batch_idx=0):\n",
    "    \"Compute performance of the model on the validation dataset and log a wandb.Table\"\n",
    "    model.eval()\n",
    "    val_loss = 0.\n",
    "    with torch.inference_mode():\n",
    "        correct = 0\n",
    "        for i, (images, labels) in enumerate(valid_dl):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass ‚û°\n",
    "            outputs = model(images)\n",
    "            val_loss += loss_func(outputs, labels)*labels.size(0)\n",
    "\n",
    "            # Compute accuracy and accumulate\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Log one batch of images to the dashboard, always same batch_idx.\n",
    "            if i==batch_idx and log_images:\n",
    "                log_image_table(images, predicted, labels, outputs.softmax(dim=1))\n",
    "    return val_loss / len(valid_dl.dataset), correct / len(valid_dl.dataset)\n",
    "\n",
    "def log_image_table(images, predicted, labels, probs):\n",
    "    \"Log a wandb.Table with (img, pred, target, scores)\"\n",
    "    # üêù Create a wandb Table to log images, labels and predictions to\n",
    "    table = wandb.Table(columns=[\"image\", \"pred\", \"target\"]+[f\"score_{i}\" for i in range(10)])\n",
    "    for img, pred, targ, prob in zip(images.to(\"cpu\"), predicted.to(\"cpu\"), labels.to(\"cpu\"), probs.to(\"cpu\")):\n",
    "        table.add_data(wandb.Image(img[0].numpy()*255), pred, targ, *prob.numpy())\n",
    "    wandb.log({\"predictions_table\":table}, commit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4sM6bi-x2i5-"
   },
   "source": [
    "## Train Your Model\n",
    "- Log metrics and visualizations\n",
    "- Log model checkpoints as artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T16:20:13.635963Z",
     "start_time": "2023-01-05T16:20:50.126Z"
    },
    "id": "AQJ278E42i5_"
   },
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"pytorch-intro\",\n",
    "    entity=\"kenlee\",\n",
    "    config={\n",
    "        \"epochs\": 5,\n",
    "        \"batch_size\": 128,\n",
    "        \"lr\": 1e-3,\n",
    "        \"dropout\": random.uniform(0.01, 0.80),\n",
    "        })\n",
    "\n",
    "# Copy your config \n",
    "config = wandb.config\n",
    "\n",
    "# Get the data\n",
    "train_dl = get_dataloader(is_train=True, batch_size=config.batch_size)\n",
    "valid_dl = get_dataloader(is_train=False, batch_size=2*config.batch_size)\n",
    "n_steps_per_epoch = math.ceil(len(train_dl.dataset) / config.batch_size)\n",
    "\n",
    "# A simple MLP model\n",
    "model = get_model(config.dropout)\n",
    "\n",
    "# Make the loss and optimizer\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n",
    "\n",
    "# Training\n",
    "example_ct = 0\n",
    "step_ct = 0\n",
    "for epoch in range(config.epochs):\n",
    "    model.train()\n",
    "    for step, (images, labels) in enumerate(train_dl):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        train_loss = loss_func(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        example_ct += len(images)\n",
    "        metrics = {\"train/train_loss\": train_loss, \n",
    "                    \"train/epoch\": (step + 1 + (n_steps_per_epoch * epoch)) / n_steps_per_epoch, \n",
    "                    \"train/example_ct\": example_ct}\n",
    "        \n",
    "        if step + 1 < n_steps_per_epoch:\n",
    "            # üêù Log train metrics to wandb \n",
    "            wandb.log(metrics)\n",
    "            \n",
    "        step_ct += 1\n",
    "\n",
    "    val_loss, accuracy = validate_model(model, valid_dl, loss_func, log_images=(epoch==(config.epochs-1)))\n",
    "\n",
    "    # üêù Log train and validation metrics to wandb\n",
    "    val_metrics = {\"val/val_loss\": val_loss, \n",
    "                    \"val/val_accuracy\": accuracy}\n",
    "    wandb.log({**metrics, **val_metrics})\n",
    "\n",
    "    # Save model checkpoint as an artifact\n",
    "    torch.save(model, \"model.pt\")\n",
    "\n",
    "    art = wandb.Artifact(f\"mnist-{wandb.run.id}\", \n",
    "                        type=\"model\",\n",
    "                        metadata={'format': 'PyTorch',\n",
    "                                  'version': '1.12.1'})\n",
    "    \n",
    "    art.add_file(\"model.pt\")\n",
    "    wandb.log_artifact(art)\n",
    "\n",
    "    \n",
    "\n",
    "# If you had a test set, this is how you could log it as a Summary metric\n",
    "wandb.summary['test_accuracy'] = 0.8\n",
    "\n",
    "# üêù Close your wandb run \n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uM9Gx-bi2i6A"
   },
   "source": [
    "You have now trained your first model using wandb! üëÜ Click on the wandb link above to see your metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFPsAG6l2i6A"
   },
   "source": [
    "# üîî Try W&B Alerts\n",
    "\n",
    "**[W&B Alerts](https://docs.wandb.ai/guides/track/alert)** allows you to send alerts, triggered from your Python code, to your Slack or email. There are 2 steps to follow the first time you'd like to send a Slack or email alert, triggered from your code:\n",
    "\n",
    "1) Turn on Alerts in your W&B [User Settings](https://wandb.ai/settings)\n",
    "\n",
    "2) Add `wandb.alert()` to your code:\n",
    "\n",
    "```python\n",
    "wandb.alert(\n",
    "    title=\"Low accuracy\", \n",
    "    text=f\"Accuracy is below the acceptable threshold\"\n",
    ")\n",
    "```\n",
    "\n",
    "See the minimal example below to see how to use `wandb.alert`. You can find the full docs for **[W&B Alerts here](https://docs.wandb.ai/guides/track/alert)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T16:20:13.636720Z",
     "start_time": "2023-01-05T16:20:50.127Z"
    },
    "id": "uijmOnQN2i6A"
   },
   "outputs": [],
   "source": [
    "# Start a wandb run\n",
    "wandb.init(project=\"pytorch-intro\")\n",
    "\n",
    "# Simulating a model training loop\n",
    "acc_threshold = 0.3\n",
    "for training_step in range(1000):\n",
    "\n",
    "    # Generate a random number for accuracy\n",
    "    accuracy = round(random.random() + random.random(), 3)\n",
    "    print(f'Accuracy is: {accuracy}, {acc_threshold}')\n",
    "    \n",
    "    # üêù Log accuracy to wandb\n",
    "    wandb.log({\"Accuracy\": accuracy})\n",
    "\n",
    "    # üîî If the accuracy is below the threshold, fire a W&B Alert and stop the run\n",
    "    if accuracy <= acc_threshold:\n",
    "        # üêù Send the wandb Alert\n",
    "        wandb.alert(\n",
    "            title='Low Accuracy',\n",
    "            text=f'Accuracy {accuracy} at step {training_step} is below the acceptable theshold, {acc_threshold}',\n",
    "        )\n",
    "        print('Alert triggered')\n",
    "        break\n",
    "\n",
    "# Mark the run as finished (useful in Jupyter notebooks)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9qhvZIM62i6B"
   },
   "source": [
    "\n",
    "# What's next üöÄ ?\n",
    "Explore other areas of the W&B platform to build a complete system of record:\n",
    "## üëâ [Log rich media (images, video, html)](https://docs.wandb.ai/guides/track/log/media) \n",
    "## üëâ [Log built-in performance plots (ROC, Confusion Matrix, etc.)](https://docs.wandb.ai/guides/track/log/plots)\n",
    "## üëâ [Log custom plots (e.g. plotly, html, matplotlib)](https://docs.wandb.ai/guides/track/log/plots#matplotlib-and-plotly-plots)\n",
    "## üëâ [Track and version datasets and models with artifacts](https://docs.wandb.ai/guides/artifacts)\n",
    "## üëâ [Hyperparameters sweeps using PyTorch](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pytorch/Organizing_Hyperparameter_Sweeps_in_PyTorch_with_W%26B.ipynb)\n",
    "## üëâ [Build Rich Reports to Document Your Work](https://docs.wandb.ai/guides/reports)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
